---
title: 'Generative AI for Beginners 시리즈 (1) - 생성형 AI란?'
date: '2025-06-01'
description: 'Microsoft의 Generative AI for Beginners 학습 후 정리하는 시리즈의 첫 번째 포스트입니다.'
tags: ['AI', '개발']
thumbnail: '/images/2025/1/BlogThumbnail.png'
---

## 1. 도입부

현재 마이크로소프트에서 생성형 AI 입문자를 위한 강의를 제공하고 있는데요. 늘 미루고 미뤘지만 이 참에 이 강의를 듣고 배운 점을 이 블로그에 함께 작성해보고자 합니다.
사실 생성형 AI를 지금도 많이 쓰고 있고 개발자로서 AI 챗봇도 만들고 있지만 사실 AI에 대해 학부 시절에 잠깐 배운 정도 제외하고는 내부적으로 어떻게 돌아가는지 또한 이걸 어떻게 구현해야할 지는 
정확히 모르는 상태였습니다. 늘 고치려고 노력하곤 있으나 개념을 먼저 정확히 알아야 이해를 하는 제 학습 스타일로 이 강의를 통해 제 머릿속을 한 번 정리하고 이를 여러분과 함께 공유하기 위해 이 시리즈를 만들어보았습니다.

링크는 [generative-ai-for-beginners](https://github.com/microsoft/generative-ai-for-beginners)를 참고해주세요.
시리즈는 총 21개까지 있으나 한 포스팅 당 하나의 시리즈는 아니고 나름 제가 정리한 부분을 토대로 포스팅할 계획입니다.

## 2. 생성형 AI란?

먼저 생성형 AI는 텍스트, 이미지 및 기타 유형의 콘텐츠를 생성할 수 있는 인공지능입니다.
누구나 손쉽게 접근할 수 있고 특히, 기존에 프로그래밍을 알아야만 할 수 있던 AI를 모두가 사용할 수 있게 해주는 혁신이라고 할 수 있습니다.

그렇다면 생성형 AI가 나오기 이전에는 어땠을까요?
사실 이 기술은 1960년대부터 시작된 기술에서 출발했습니다.

`typewritten` 챗봇과 같은 최초의 AI 프로토타입은 전문가 그룹에서 추출한 지식 베이스를 컴퓨터에 표현하고, 입력 텍스트에 나타나는 키워드에 의해 지식 베이스의 답변이 트리거되는 방식으로 구성되었습니다.

그러나 이 방식은 결국 지식 베이스를 구성하는 것이 매우 복잡하고 유지보수하기 어려웠습니다.

### AI에 대한 통계적 접근의 시작 : 머신러닝

90년대에 새로운 전환점을 발견했습니다. 바로 텍스트 분석에 통계적 접근법을 적용한 것이었습니다. 이로 인해 새로운 알고리즘들이 개발되었는데, 이를 **머신러닝** 이라고 불렀습니다.
이 알고리즘들은 명시적으로 프로그래밍되지 않아도 데이터로부터 패턴을 학습할 수 있었습니다.

통계 모델은 텍스트-레이블 쌍에 대해 학습하며, 이를 통해 모델은 알려지지 않은 입력 텍스트를 메시지의 의도를 나타내는 사전 정의된 레이블로 분류할 수 있게 됩니다.

### 신경망과 현대의 가상 어시스턴트

최근에는 더 많은 양의 데이터를 처리하고 더 복잡한 계산을 수행할 수 있는 하드웨어의 발전이 AI 분야의 연구를 촉진시켰고, 이로 인해 고급 머신러닝 알고리즘인
딥러닝 알고리즘이 개발되었습니다.

신경망은 자연어 처리를 크게 향상시켜, 단어의 문맥을 고려하여 텍스트의 의미를 더 의미있게 표현할 수 있게 되었습니다.

이 기술은 `어시스턴트`의 등장을 알렸으며, 인간의 언어를 해석하고, 필요성을 파악하고, 그것을 만족시키기 위한 행동을 수행하는데 매우 능숙했습니다.

이러한 기술들의 발전이 결국 현재의 생성형 AI를 탄생시켰습니다. 즉, 생성형 AI는 딥러닝의 하위 분야로 불 수 있습니다.

특히 새로운 모델 구조인 `Transformer`가 RNN(순환 신경망)의 한계를 극복하고 새로운 혁신을 가져왔습니다.
Transformer는 입력받은 텍스트 순서의 간계 없이 가장 중요한 정보가 집중된 곳에 `더 많은 주의`를 기울일 수 있도록 모델에 다른 가중치를 부여하는 `attention` 메커니즘에 기반합니다.

우리가 지금까지 사용하고 있는 LLM들은 대부분 이 구조를 기반으로 두고 있습니다. 특히 이 모델들은 책, 기사, 웹사이트 등 다양한 출처로부터 수많은 양의 라벨이 없는 데이터로 훈련되었습니다.
심지어 문법적으로 올바르고 창의적인 텍스트를 생성할 수도 있습니다. 즉 기계와 인간의 소통 방식을 **인간의 언어**로 확장시키는데 큰 기여를 했다고 볼 수 있습니다.

![image](/images/2025/9/AI-diagram.png)

## LLM (대형 언어 모델)의 작동 방식

- **토크나이저, 텍스트 -> 숫자** : 대형 언어 모델은 텍스트를 입력으로 받아 텍스트를 출력합니다. 하지만 `통계적 모델` 이기 때문에 텍스트 시퀀스보다는 숫자로 작업하는 것이 훨씬 더 유리합니다.
그래서 모델의 핵심 부분이 사용하기 전에 모든 입력은 토크나이저에 의해 처리됩니다. 토큰은 텍스트의 조각으로, 일정한 수의 문자로 구성됩니다. 그래서 토크나이저의 주요 작업은 입력을 `토큰 배열`로 분할 하는 것입니다.
그런 다음 각 토큰은 토큰 인덱스와 매핑됩니다. 토큰 인덱스는 원래 텍스트 조각의 정수 인코딩입니다.

![image](/images/2025/9/tokenizer-example.png)

- **출력 토큰 예측하기** : 그 후 n개의 토큰을 입력 받았으면 모델은 하나의 토큰을 출력으로 예측할 수 있습니다. 이 토큰은 다음 반복의 입력에 확장 윈도우 패턴을 통해 더 나은 사용자 경험을 제공하여 여러 문장을 답변으로 얻을 수 있습니다.

**확장 윈도우 패턴** : 확장 윈도우 패턴을 이해하기 전에 크게 `윈도우`와 `확장`에 대해 이해해야 합니다.
 - `윈도우` : 윈도우는 한 번에 모델이 처리할 수 있는 토큰 길이를 의미합니다.
 - `확장` : 텍스트 생성 시, 모델은 각 반복에서 한 개 혹은 그 이상의 토큰을 출력합니다. 출력된 토큰은 다음 입력 시 윈도우의 뒤쪽에 추가되고, 이로 인해 입력 윈도우의 범위가 점점 앞으로 확장됩니다. 그래서 모델은 직전 생성할 결과까지 포함된 새로운 입력을 받아, 문맥을 유지하며 계속 이어가는 것처럼 텍스트를 생성합니다.
 결론적으로 확장 윈도우 패턴은 모델이 매번 입력(윈도우)으로 n개의 토큰을 받아 처리한 후, 출력된 토큰을 입력 윈도우에 추가하여 점점 더 긴 문맥을 형성하는 패턴입니다.

 이렇게 하는 이유는 메모리와 계산량을 줄이면서도 긴 문맥을 유지하기 위함인데, GPT 초기에 한 번에 긴 답변을 모두 출력하지 않고, 중간에 멈추고 이어지는 것처럼 보였던 이유이기도 합니다.

 - **언어 모델의 다음 단어 선택 과정** : 언어 모델은 한 번에 한 단어(혹은 그보다 작은 단위의 토큰)를 생성합니다. 하지만 이 선택은 무작위로 이루어지는 것이 아니라, 모델이 학습한 내용을 기반으로 "이 상황에서 다음 단어로 나올 가능성이 높은 단어"를 계산하여 그 확률 분포를 예측합니다.

즉, 모델은 현재까지의 문맥을 보고 다음 단어의 후보들을 선택하며, 각 후보에 확률을 부여합니다. 이를 확률 분포라고 합니다.

그러나 항상 가장 높은 확률을 가진 단어를 선택하면 결과가 너무 정형화되고 예측 가능하게 됩니다. 그래서 모델은 여기에 약간의 무작위성을 더합니다. 이를 통해 동일한 입력이어도 매번 조금씩 다른 결과를 생성할 수 있게 됩니다.

이 무작위성의 정도는 **temperature(온도)**라는 설정값으로 조정됩니다.

temperature 값이 낮으면(예: 0.1~0.3) 높은 확률의 단어가 거의 항상 선택되어 결과가 일관되지만 창의성은 떨어집니다.

temperature 값이 높으면(예: 0.8~1.0) 낮은 확률의 단어도 선택될 가능성이 커지므로 더 창의적이지만 예측은 어렵습니다.

따라서 모델은 학습한 확률 분포와 temperature를 조합하여 다음 단어를 선택합니다.


